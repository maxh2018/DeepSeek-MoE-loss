{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch ,math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoEGate(nn.Module):\n",
    "    def __init__(self):#, config\n",
    "        super().__init__()\n",
    "        #添加的额外参数\n",
    "        self.CommBal=True\n",
    "        self.n_routed_experts=8\n",
    "        self.alpha2 = 0.001         #config.aux_loss_alpha\n",
    "        self.alpha3 = 0.001         #config.aux_loss_alpha\n",
    "        self.training=True\n",
    "        self.DevBal=True\n",
    "        self.CommBal=True\n",
    "        self.M=1\n",
    "        self.D=4\n",
    "\n",
    "        #self.config = config\n",
    "        self.top_k = 2 #config.num_experts_per_tok\n",
    "        #self.n_routed_experts = config.n_routed_experts\n",
    "\n",
    "        self.scoring_func =\"softmax\"   #config.scoring_func\n",
    "        self.alpha =0.001          #config.aux_loss_alpha\n",
    "        self.seq_aux =False #config.seq_aux\n",
    "\n",
    "        # topk selection algorithm\n",
    "        self.norm_topk_prob =False #config.norm_topk_prob\n",
    "        self.gating_dim =12 #config.hidden_size\n",
    "        self.weight = nn.Parameter(torch.empty((self.n_routed_experts, self.gating_dim)))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        import torch.nn.init  as init\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        #print(\"self.weight=\",self.weight)\n",
    "    def forward(self, hidden_states):\n",
    "            bsz, seq_len, h = hidden_states.shape        \n",
    "            ### compute gating score\n",
    "            hidden_states = hidden_states.view(-1, h)\n",
    "            logits = F.linear(hidden_states, self.weight, None)\n",
    "            if self.scoring_func == 'softmax':\n",
    "                scores = logits.softmax(dim=-1)\n",
    "            else:\n",
    "                raise NotImplementedError(f'insupportable scoring function for MoE gating: {self.scoring_func}')\n",
    "            \n",
    "            ### select top-k experts\n",
    "            topk_weight, topk_idx = torch.topk(scores, k=self.top_k, dim=-1, sorted=False)\n",
    "            \n",
    "            ### norm gate to sum 1\n",
    "            if self.top_k > 1 and self.norm_topk_prob:\n",
    "                denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20\n",
    "                topk_weight = topk_weight / denominator\n",
    "            #print(\"topk_idx=\\n\",topk_idx,\"\\n\")\n",
    "            ### expert-level computation auxiliary loss\n",
    "            if self.training and self.alpha > 0.0:\n",
    "                scores_for_aux = scores  #(bsz*seq_len,n_routed_experts)\n",
    "                aux_topk = self.top_k\n",
    "                # always compute aux loss based on the naive greedy topk method\n",
    "                topk_idx_for_aux_loss = topk_idx.view(bsz, -1) #(bsz,seq_len*k)\n",
    "                if self.seq_aux:\n",
    "                    scores_for_seq_aux = scores_for_aux.view(bsz, seq_len, -1)\n",
    "                    ce = torch.zeros(bsz, self.n_routed_experts, device=hidden_states.device)\n",
    "                    ce.scatter_add_(1, topk_idx_for_aux_loss, torch.ones(bsz, seq_len * aux_topk, device=hidden_states.device)).div_(seq_len * aux_topk / self.n_routed_experts)\n",
    "                    aux_loss = (ce * scores_for_seq_aux.mean(dim = 1)).sum(dim = 1).mean() * self.alpha\n",
    "                if self.DevBal:\n",
    "                    scores_for_seq_aux = scores_for_aux.view(bsz, seq_len, -1) #(bsz,seq_len,n_routed_experts)\n",
    "                    #print(\"scores_for_seq_aux=\\n\",scores_for_seq_aux,\"\\n\")\n",
    "                    Pi_tensor=scores_for_seq_aux.mean(dim = 1) #(bsz,self.n_routed_experts)\n",
    "                    #print(\"Pi_tensor=\\n\",Pi_tensor,\"\\n\")\n",
    "                    ce = torch.zeros(bsz, self.n_routed_experts, device=hidden_states.device)\n",
    "                    ce.scatter_add_(1, topk_idx_for_aux_loss, torch.ones(bsz, seq_len * aux_topk, device=hidden_states.device)).div_(seq_len * aux_topk / self.n_routed_experts)\n",
    "                    fi_tensor=ce  #(bsz,self.n_routed_experts)\n",
    "                    #print(f\"fi_tensor=({fi_tensor.size()})\\n\",fi_tensor,\"\\n\")\n",
    "                    \n",
    "                    D_group_expert_list=[]#list(range(self.n_routed_experts))\n",
    "                    P_i_list=[]\n",
    "                    D=4\n",
    "                    assert self.n_routed_experts%D==0\n",
    "                    step=int(self.n_routed_experts/D)\n",
    "                    for i in range(0,self.n_routed_experts,step):\n",
    "                        D_group_expert_list.append(fi_tensor[:,i:i+step].mean(dim=-1,keepdim=True)) ######\n",
    "                        P_i_list.append(Pi_tensor[:,i:i+step].sum(dim=-1,keepdim=True))\n",
    "                    fi__total_tensor,P_i_total_tensor=None,None    \n",
    "                    for ele in D_group_expert_list:\n",
    "                        if fi__total_tensor is None:\n",
    "                            fi__total_tensor=ele\n",
    "                        else:\n",
    "                            fi__total_tensor=torch.cat((fi__total_tensor,ele),dim=-1)  #(bsz,D)\n",
    "                    #print(\"程序输出的fi__total_tensor=\\n\",fi__total_tensor)\n",
    "                    for ele in P_i_list:\n",
    "                        if  P_i_total_tensor is None:\n",
    "                            P_i_total_tensor=ele\n",
    "                        else:\n",
    "                            P_i_total_tensor=torch.cat((P_i_total_tensor,ele),dim=-1) #(bsz,D)\n",
    "                    #print(\"程序输出的P_i_total_tensor=\\n\",P_i_total_tensor)\n",
    "                    #print(\"fi__total_tensor*P_i_total_tensor=\\n\",fi__total_tensor*P_i_total_tensor)\n",
    "                    DevBal_loss=(fi__total_tensor*P_i_total_tensor).sum(dim=1).mean()* self.alpha2\n",
    "                if self.CommBal:\n",
    "                    scores_for_seq_aux = scores_for_aux.view(bsz, seq_len, -1) #(bsz, seq_len, n_routed_experts)\n",
    "                    #print(\"scores_for_seq_aux=\\n\",scores_for_seq_aux,\"\\n\")\n",
    "                    raw=topk_idx.view(bsz,seq_len, -1) #(bsz, seq_len, k)\n",
    "                    #print(\"topk_idx.view=\\n\",raw,\"\\n\")\n",
    "                    assert self.n_routed_experts%D==0\n",
    "                    step=int(self.n_routed_experts/D)\n",
    "                    #print(\"before raw=\\n\",raw)\n",
    "                    raw=raw//step\n",
    "                    #print(\"raw=\\n\",raw)\n",
    "                    new=torch.zeros(bsz,D)\n",
    "                    for i in range(D):\n",
    "                        tem= (raw==i).any(dim=-1).sum(dim=-1)\n",
    "                        new[:,i]=tem\n",
    "                    #print(\"new=\",new)\n",
    "                    new=new*D/(seq_len*self.M)\n",
    "                    Pi_tensor=scores_for_seq_aux.mean(dim = 1) #(bsz,self.n_routed_experts)\n",
    "                    P_i_list=[]\n",
    "                    D=4\n",
    "                    for i in range(0,self.n_routed_experts,step):\n",
    "                        P_i_list.append(Pi_tensor[:,i:i+step].sum(dim=-1,keepdim=True))\n",
    "                    P_i_total_tensor=None\n",
    "                    for ele in P_i_list:\n",
    "                        if  P_i_total_tensor is None:\n",
    "                            P_i_total_tensor=ele\n",
    "                        else:\n",
    "                            P_i_total_tensor=torch.cat((P_i_total_tensor,ele),dim=-1)\n",
    "                    CommBal_loss=(new*P_i_total_tensor).sum(dim=1).mean()* self.alpha3               \n",
    "            #else:\n",
    "            #    aux_loss,DevBal_loss = None,None\n",
    "            return topk_idx, topk_weight,DevBal_loss,CommBal_loss  # aux_loss,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [5, 1],\n",
       "         [0, 1],\n",
       "         [5, 1],\n",
       "         [0, 7],\n",
       "         [0, 5]]),\n",
       " tensor([[0.2090, 0.1785],\n",
       "         [0.1512, 0.1503],\n",
       "         [0.1807, 0.1608],\n",
       "         [0.1787, 0.1651],\n",
       "         [0.1555, 0.1324],\n",
       "         [0.1614, 0.1492]], grad_fn=<TopkBackward0>),\n",
       " tensor(0.0012, grad_fn=<MulBackward0>),\n",
       " tensor(0.0019, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOE=MoEGate()\n",
    "bsz, seq_len, h=(2,3,12)\n",
    "hidden_states=torch.rand((bsz, seq_len, h))\n",
    "MOE(hidden_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
